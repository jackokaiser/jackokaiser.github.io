---
layout: archive
title: "Work Experiences"
permalink: /work-experiences/
author_profile: true
---

DeepScenario (_2021 - current_)
-----

Powered by deep learning, [DeepScenario](https://www.deepscenario.com/) processes video data recorded by drones fyling over roads.
We provide the resulting real-world traffic data to help companies improve their autonomous driving algorithms.
My main focus in this startup is to improve the performance of the deep learning model.

Tech4Gaïa: Noehmi by ocellus (_November 2020 - February 2021_)
-----

The focus of [Tech4Gaïa](https://www.tech4gaia.com/) is to develop a smart beehive device called [Noehmi](http://noehmi.com/).
This device includes sensors to monitor the health of the bee colony, and actuators performing simple beekeeping tasks.
I have developed for this startup the first prototype mobile web application, including:
- setting up a node.js backend using the [loopback](https://loopback.io/) framework
- wiring up a PostgreSQL database with [timescale extension](https://www.timescale.com/)
- bidirectional communication between devices and the backend with MQTT messages encoded with protobuf
- development of a PWA frontend with vue.js
- docker-based deployment

**Reference - [Farid Maniani](https://fr.linkedin.com/in/farid-maniani-%F0%9F%90%9D-08508517b)**

FZI research center for information technology (_2015-2020_)
-----

Robotics engineer position at [FZI research center for information technology](http://www.fzi.de/en/home/ "FZI"), while simultaneously pursuing a PhD within the [Human Brain Project](http://www.fzi.de/en/research/projekt-details/human-brain-project/ "Human Brain Project at FZI") in [Neurorobotics](https://neurorobotics.net "Neurorobotics in the Human Brain Project") at Karlsruher Institut für Technologie (KIT).

As a robotics engineer, I was involved in a variety of robotics projects, with a focus on computer vision, machine learning and web development.

As a PhD student, I have developed spiking network models to learn robot control from event-based vision.
I have also participated in the development of the Neurorobotics platform, a web-app wiring brain simulations with robotic simulations.
In this [blog post](/posts/2020/08/synaptic-learning) I briefly describe my PhD thesis.

**Reference - [Prof. Dr. Rüdiger Dillmann](https://www.fzi.de/de/wir-ueber-uns/organisation/mitarbeiter/address/ruediger-dillmann/)**

Shwish (_February-July 2014_)
-----

Shwish is an Australian startup providing an online collaborative gifting platform, that is like Kickstarter for your friends' wishes and projects.

Part of a small team, I had the chance to work on every side of the project: design implementation, front-end, back-end, database and devOps.
The web-app was built upon the popular MEAN stack: MongoDB, Express.Js, AngularJS, Node.js.

**Reference - [Roger Ouk](https://www.oukdigital.com.au/roger-ouk)**

Skimlab (_June-October 2013_)
-----

Internship of 5 months in [skimlab](http://www.skimlab.com/ "skimlab"), a startup providing web-based 3D modelling tools.

The business model is to provide an easy online tool for modelling 3D objects which relies on implicit surface.
Thanks to the implicit surfaces, designed 3D models are certified to be 3D printable, since their volume is mathematically defined.
Users can therefore 3D print their models, which are shipped to them.
The startup also released [jweel](https://www.jweel.com/en/ "jweel"), a similar platform focusing on the design of jewelry.

I worked on WebGL shader development to enhance and speed up rendering.
It involved good knowledge of JavaScript, Three.js, glsl and WebGL.

**Reference - [Maxime Quiblier](https://fr.linkedin.com/in/maxime-quiblier-25959a9)**

iCube (_June-August 2012_)
-----

During this internship, I developed an application for mesh editing on a virtual reality platform.
In order to be realtime, I built it upon [CGoGN](http://cgogn.unistra.fr/ "CGoGN"), a powerful library that provides an efficient implementation of combinatorial maps, maintained by the iCube laboratory.

We used the user avatar optimized for depth perception which I developed during my previous intership at the lab.

**Reference - [Jérôme Grosjean](https://dpt-info.di.unistra.fr/~grosjean/)**

iCube (_June-August 2011_)
-----

Desptite the improvments of 3D technologies, it remains hard to guess relative depth of objects in space.
I implemented solutions where the cursor (the user avatar) gives hints on its position by scaling and orienting itself toward the closest object in space.
We tryed out many different shapes and textures to find out the one yielding the best depth perception.
The final version of the cursor has successfully been used for terrain editing on a 3D workbench platform.

**Reference - [Jérôme Grosjean](https://dpt-info.di.unistra.fr/~grosjean/)**
